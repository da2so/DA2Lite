PRUNING:
  POST_TRAIN:
    IS_USE: True # Use post-train after pruning?
    NAME: basic # Choice of ['basic', 'fskd']
    OPTIMIZER: sgd # Choice of ['sgd', 'adam']
    OPTIMIZER_ARGS:  # Arguments of a choosed optimizer
      MOMENTUM: 0.9 #for sgd
      WEIGHT_DECAY: 5e-4 #for sgd
      """
      BETAS: (0.9, 0.999) for adam
      EPSILON: 1e-8  for adam
      """
    LOSS: categorical_crossentropy # Choice of [categorical_crossentropy, kld, mae, mse]
    SCHEDULER: cosineannealLR # [stepLR, exponentialLR, cosineannealLR]
    SCHEDULER_ARGS:  # Arguments of a choosed scheduler
      T_MAX: 30 #for 
      """
      STEP_SIZE: 60 # for stepLR
      GAMMA: 0.1 # for stepLR

      GAMMA: 0.95 # for exponentialLR
      """
    BATCH_SIZE: 256 # Batch size
    EPOCHS: 30 # Epochs
    LR: 0.001 # Learning rate
  
  METHOD:
    CRITERIA: EagleEye # Choice of ['EagleEye', 'Slimming', 'L1Criteria', 'L2Criteria', 'RandomCriteria']
    CRITERIA_ARGS: 
      NUM_CANDIDATES: 20 # for EagleEye
    STRATEGY: MinMaxStrategy # Choice of ['MinMaxStrategy', 'RandomStrategy', 'StaticStrategy']
    STRATEGY_ARGS:
      PRUNING_RATIO: [0.0, 0.5] # for MinMaxStrategy
      """
      PRUNING_RATIO: None # for RandomStrategy

      PRUNING_RATIO: [0.5] # for StaticStrategy
      """

FD:
  POST_TRAIN:
    IS_USE: True # Use post-train after filter decomposition??
    NAME: basic # Choice of ['basic', 'fskd']
    OPTIMIZER: sgd
    OPTIMIZER_ARGS:
      MOMENTUM: 0.9
      WEIGHT_DECAY: 5e-4
    LOSS: categorical_crossentropy 
    SCHEDULER: cosineannealLR 
    SCHEDULER_ARGS:
      T_MAX: 30
    BATCH_SIZE: 256
    EPOCHS: 30
    LR: 0.001
  
  METHOD:
    DECOMPOSITION: Tucker # Choice of ['Tucker', 'CP']
    START_IDX: 6 # Start index of filter decomposition (based on an order of conv layer)
    RANK: 6 # Choice of ['4', '5', '6', 'VBMF']

